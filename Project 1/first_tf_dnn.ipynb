{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow solution to Project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing modules and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = 'Bike-Sharing-Dataset/hour.csv'\n",
    "\n",
    "rides = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
       "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
       "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
       "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
       "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
       "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
       "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
       "4           1  0.24  0.2879  0.75        0.0       0           1    1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rides.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "      <th>season_1</th>\n",
       "      <th>season_2</th>\n",
       "      <th>...</th>\n",
       "      <th>hr_21</th>\n",
       "      <th>hr_22</th>\n",
       "      <th>hr_23</th>\n",
       "      <th>weekday_0</th>\n",
       "      <th>weekday_1</th>\n",
       "      <th>weekday_2</th>\n",
       "      <th>weekday_3</th>\n",
       "      <th>weekday_4</th>\n",
       "      <th>weekday_5</th>\n",
       "      <th>weekday_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   yr  holiday  temp   hum  windspeed  casual  registered  cnt  season_1  \\\n",
       "0   0        0  0.24  0.81        0.0       3          13   16         1   \n",
       "1   0        0  0.22  0.80        0.0       8          32   40         1   \n",
       "2   0        0  0.22  0.80        0.0       5          27   32         1   \n",
       "3   0        0  0.24  0.75        0.0       3          10   13         1   \n",
       "4   0        0  0.24  0.75        0.0       0           1    1         1   \n",
       "\n",
       "   season_2    ...      hr_21  hr_22  hr_23  weekday_0  weekday_1  weekday_2  \\\n",
       "0         0    ...          0      0      0          0          0          0   \n",
       "1         0    ...          0      0      0          0          0          0   \n",
       "2         0    ...          0      0      0          0          0          0   \n",
       "3         0    ...          0      0      0          0          0          0   \n",
       "4         0    ...          0      0      0          0          0          0   \n",
       "\n",
       "   weekday_3  weekday_4  weekday_5  weekday_6  \n",
       "0          0          0          0          1  \n",
       "1          0          0          0          1  \n",
       "2          0          0          0          1  \n",
       "3          0          0          0          1  \n",
       "4          0          0          0          1  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_fields = ['season', 'weathersit', 'mnth', 'hr', 'weekday']\n",
    "for each in dummy_fields:\n",
    "    dummies = pd.get_dummies(rides[each], prefix=each, drop_first=False)\n",
    "    rides = pd.concat([rides, dummies], axis=1)\n",
    "\n",
    "fields_to_drop = ['instant', 'dteday', 'season', 'weathersit', \n",
    "                  'weekday', 'atemp', 'mnth', 'workingday', 'hr']\n",
    "data = rides.drop(fields_to_drop, axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quant_features = ['casual', 'registered', 'cnt', 'temp', 'hum', 'windspeed']\n",
    "# Store scalings in a dictionary so we can convert back later\n",
    "scaled_features = {}\n",
    "for each in quant_features:\n",
    "    mean, std = data[each].mean(), data[each].std()\n",
    "    scaled_features[each] = [mean, std]\n",
    "    data.loc[:, each] = (data[each] - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save data for approximately the last 21 days \n",
    "test_data = data[-21*24:]\n",
    "\n",
    "# Now remove the test data from the data set \n",
    "data = data[:-21*24]\n",
    "\n",
    "# Separate the data into features and targets\n",
    "target_fields = ['cnt', 'casual', 'registered']\n",
    "features, targets = data.drop(target_fields, axis=1), data[target_fields]\n",
    "test_features, test_targets = test_data.drop(target_fields, axis=1), test_data[target_fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hold out the last 60 days or so of the remaining data as a validation set\n",
    "train_features, train_targets = features[:-60*24], targets[:-60*24]\n",
    "val_features, val_targets = features[-60*24:], targets[-60*24:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a single layer neural network with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neural_net(input, num_features):\n",
    "    # Build input layer\n",
    "    labels_count = 1\n",
    "\n",
    "    num_hidden = 8\n",
    "\n",
    "    weights_i_h = tf.Variable(tf.truncated_normal((num_features, num_hidden)))\n",
    "    biases_i_h = tf.Variable(tf.zeros(num_hidden))\n",
    "\n",
    "    weights_h_o = tf.Variable(tf.truncated_normal((num_hidden, labels_count)))\n",
    "    biases_h_o = tf.Variable(tf.zeros(labels_count))\n",
    "    \n",
    "    logits_i_h = tf.matmul(inputs, weights_i_h) + biases_i_h # when to use tf.add?\n",
    "    sigmoid_i_h = tf.nn.sigmoid(logits_i_h, name=None)\n",
    "\n",
    "    prediction = tf.matmul(sigmoid_i_h, weights_h_o) + biases_h_o\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_neural_network(x, num_features):\n",
    "    prediction = neural_net(x, num_features) #feed-forward\n",
    "    loss = tf.reduce_mean(tf.squared_difference(prediction, label))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(loss)    # default learning_rate = 0.001\n",
    "\n",
    "    # cycles of feedforwards + backprop\n",
    "    hm_epochs = 10000\n",
    "    training_fd = {inputs: train_features, label: train_targets[\"cnt\"][:,None]}\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(hm_epochs):      \n",
    "            _, c = sess.run([optimizer, loss], feed_dict = training_fd)\n",
    "            if (epoch % 1000 == 0 or epoch == 9999):\n",
    "                print(\"Epoch\", epoch, \"completed out of\", hm_epochs, \"loss:\", c)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_features = train_features.shape[1]\n",
    "labels_count = 1\n",
    "inputs = tf.placeholder(tf.float32, [None, num_features])\n",
    "label = tf.placeholder(tf.float32, [None, labels_count])\n",
    "train_neural_network(inputs, num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Adding more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def two_hidden_layer_nn(input, num_features):\n",
    "    # Build input layer\n",
    "    labels_count = 1\n",
    "\n",
    "    # layer 1\n",
    "    num_hidden_1 = 8\n",
    "    weights_i_h1 = tf.Variable(tf.truncated_normal((num_features, num_hidden_1)))\n",
    "    biases_i_h1 = tf.Variable(tf.zeros(num_hidden_1))\n",
    "    logits_i_h1 = tf.matmul(inputs, weights_i_h1) + biases_i_h1 # when to use tf.add?\n",
    "    sigmoid_i_h1 = tf.nn.sigmoid(logits_i_h1, name=None)\n",
    "    \n",
    "    #layer 2\n",
    "    num_hidden_2 = 8\n",
    "    weights_h1_h2 = tf.Variable(tf.truncated_normal((num_hidden_1, num_hidden_2)))\n",
    "    biases_h1_h2 = tf.Variable(tf.zeros(num_hidden_2))\n",
    "    logits_h1_h2 = tf.matmul(sigmoid_i_h1, weights_h1_h2) + biases_h1_h2 # when to use tf.add?\n",
    "    sigmoid_h1_h2 = tf.nn.sigmoid(logits_h1_h2, name=None)\n",
    "    \n",
    "    #output\n",
    "    weights_h2_o = tf.Variable(tf.truncated_normal((num_hidden_2, labels_count)))\n",
    "    biases_h2_o = tf.Variable(tf.zeros(labels_count))\n",
    "    prediction = tf.matmul(sigmoid_h1_h2, weights_h2_o) + biases_h2_o\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_two_hidden_nn(x, num_features):\n",
    "    prediction = two_hidden_layer_nn(x, num_features) #feed-forward\n",
    "    loss = tf.reduce_mean(tf.squared_difference(prediction, label))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(loss)    # default learning_rate = 0.001\n",
    "\n",
    "    # cycles of feedforwards + backprop\n",
    "    hm_epochs = 10000\n",
    "    training_fd = {inputs: train_features, label: train_targets[\"cnt\"][:,None]}\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in tqdm(range(hm_epochs)):      \n",
    "            _, c = sess.run([optimizer, loss], feed_dict = training_fd)\n",
    "            if (epoch % 1000 == 0 or epoch == 9999):\n",
    "                print(\"Epoch\", epoch, \"completed out of\", hm_epochs, \"loss:\", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_two_hidden_nn(inputs, num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactor code to allow for saving and loading models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, build the computational graph. The cell below is to be copy-pasted when loading a pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Building the computational graph\n",
    "num_features = train_features.shape[1]\n",
    "labels_count = 1\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, [None, num_features])\n",
    "label = tf.placeholder(tf.float32, [None, labels_count])\n",
    "\n",
    "\n",
    "num_hidden_1 = 8\n",
    "num_hidden_2 = 8\n",
    "\n",
    "weights_i_h1 = tf.Variable(tf.truncated_normal((num_features, num_hidden_1)))\n",
    "biases_i_h1 = tf.Variable(tf.zeros(num_hidden_1))\n",
    "weights_h1_h2 = tf.Variable(tf.truncated_normal((num_hidden_1, num_hidden_2)))\n",
    "biases_h1_h2 = tf.Variable(tf.zeros(num_hidden_2))\n",
    "weights_h2_o = tf.Variable(tf.truncated_normal((num_hidden_2, labels_count)))\n",
    "biases_h2_o = tf.Variable(tf.zeros(labels_count))\n",
    "\n",
    "logits_i_h1 = tf.matmul(inputs, weights_i_h1) + biases_i_h1 # when to use tf.add?\n",
    "sigmoid_i_h1 = tf.nn.sigmoid(logits_i_h1, name=None)\n",
    "\n",
    "logits_h1_h2 = tf.matmul(sigmoid_i_h1, weights_h1_h2) + biases_h1_h2 # when to use tf.add?\n",
    "sigmoid_h1_h2 = tf.nn.sigmoid(logits_h1_h2, name=None)\n",
    "\n",
    "prediction = tf.matmul(sigmoid_h1_h2, weights_h2_o) + biases_h2_o\n",
    "loss = tf.reduce_mean(tf.squared_difference(prediction, label))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(loss)    # default learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next train the model, construct a dictionary containing all the model parameters (numpy) as values and the filenames as keys. Save all variables in the dictionary as numpy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/10000 [00:00<05:20, 31.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 completed out of 10000 loss: 1.28179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1007/10000 [00:23<03:21, 44.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 completed out of 10000 loss: 0.345041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2009/10000 [00:46<02:40, 49.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2000 completed out of 10000 loss: 0.244909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3008/10000 [01:07<02:22, 49.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3000 completed out of 10000 loss: 0.213803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4009/10000 [01:27<02:02, 48.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4000 completed out of 10000 loss: 0.181588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5007/10000 [01:48<01:40, 49.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5000 completed out of 10000 loss: 0.152602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6007/10000 [02:08<01:21, 49.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6000 completed out of 10000 loss: 0.129304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7007/10000 [02:29<01:02, 48.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7000 completed out of 10000 loss: 0.110583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8007/10000 [02:49<00:40, 49.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8000 completed out of 10000 loss: 0.097107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9007/10000 [03:10<00:20, 48.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9000 completed out of 10000 loss: 0.0880489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [03:31<00:00, 49.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9999 completed out of 10000 loss: 0.0818711\n",
      "saving variables...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "# cycles of feedforwards + backprop\n",
    "hm_epochs = 10000\n",
    "training_fd = {inputs: train_features, label: train_targets[\"cnt\"][:,None]}\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in tqdm(range(hm_epochs)):      \n",
    "        _, c = sess.run([optimizer, loss], feed_dict = training_fd)\n",
    "        if (epoch % 1000 == 0 or epoch == 9999):\n",
    "            print(\"Epoch\", epoch, \"completed out of\", hm_epochs, \"loss:\", c)\n",
    "    print(\"saving variables...\")\n",
    "    param_dict = {\"wih1.npy\": weights_i_h1, \"bih1\": biases_i_h1, \"wh1h2\": weights_h1_h2, \n",
    "                  \"bh1h2\": biases_h1_h2, \"wh20\": weights_h2_o, \"bh20\": biases_h2_o}\n",
    "    for file, param in param_dict.items():\n",
    "        np.save(file, param.eval())\n",
    "    print(\"Done!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cell below can be run by itself. First, copy and paste the graph structure. This time, instead of randomly initialising values, load the numpy arrays back into the model parameter variables. Finally, run the graph as per normal with the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running prediction...\n",
      "0.228952\n"
     ]
    }
   ],
   "source": [
    "import load\n",
    "\n",
    "num_features = train_features.shape[1]\n",
    "labels_count = 1\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, [None, num_features])\n",
    "label = tf.placeholder(tf.float32, [None, labels_count])\n",
    "\n",
    "params_dict = load.run()\n",
    "weights_i_h1 = tf.Variable(params_dict[\"wih1\"])\n",
    "biases_i_h1 = tf.Variable(params_dict[\"bih1\"])\n",
    "weights_h1_h2 = tf.Variable(params_dict[\"wh1h2\"])\n",
    "biases_h1_h2 = tf.Variable(params_dict[\"bh1h2\"])\n",
    "weights_h2_o = tf.Variable(params_dict[\"wh20\"])\n",
    "biases_h2_o = tf.Variable(params_dict[\"bh20\"])\n",
    "\n",
    "logits_i_h1 = tf.matmul(inputs, weights_i_h1) + biases_i_h1 # when to use tf.add?\n",
    "sigmoid_i_h1 = tf.nn.sigmoid(logits_i_h1, name=None)\n",
    "\n",
    "logits_h1_h2 = tf.matmul(sigmoid_i_h1, weights_h1_h2) + biases_h1_h2 # when to use tf.add?\n",
    "sigmoid_h1_h2 = tf.nn.sigmoid(logits_h1_h2, name=None)\n",
    "\n",
    "prediction = tf.matmul(sigmoid_h1_h2, weights_h2_o) + biases_h2_o\n",
    "loss = tf.reduce_mean(tf.squared_difference(prediction, label))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    testing_fd = {inputs: test_features, label: test_targets[\"cnt\"][:,None]}\n",
    "    print(\"running prediction...\")\n",
    "    print(sess.run(loss, feed_dict=testing_fd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "py35",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
