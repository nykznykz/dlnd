{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = 'Bike-Sharing-Dataset/hour.csv'\n",
    "\n",
    "rides = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
       "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
       "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
       "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
       "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
       "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
       "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
       "4           1  0.24  0.2879  0.75        0.0       0           1    1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rides.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "      <th>season_1</th>\n",
       "      <th>season_2</th>\n",
       "      <th>...</th>\n",
       "      <th>hr_21</th>\n",
       "      <th>hr_22</th>\n",
       "      <th>hr_23</th>\n",
       "      <th>weekday_0</th>\n",
       "      <th>weekday_1</th>\n",
       "      <th>weekday_2</th>\n",
       "      <th>weekday_3</th>\n",
       "      <th>weekday_4</th>\n",
       "      <th>weekday_5</th>\n",
       "      <th>weekday_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   yr  holiday  temp   hum  windspeed  casual  registered  cnt  season_1  \\\n",
       "0   0        0  0.24  0.81        0.0       3          13   16         1   \n",
       "1   0        0  0.22  0.80        0.0       8          32   40         1   \n",
       "2   0        0  0.22  0.80        0.0       5          27   32         1   \n",
       "3   0        0  0.24  0.75        0.0       3          10   13         1   \n",
       "4   0        0  0.24  0.75        0.0       0           1    1         1   \n",
       "\n",
       "   season_2    ...      hr_21  hr_22  hr_23  weekday_0  weekday_1  weekday_2  \\\n",
       "0         0    ...          0      0      0          0          0          0   \n",
       "1         0    ...          0      0      0          0          0          0   \n",
       "2         0    ...          0      0      0          0          0          0   \n",
       "3         0    ...          0      0      0          0          0          0   \n",
       "4         0    ...          0      0      0          0          0          0   \n",
       "\n",
       "   weekday_3  weekday_4  weekday_5  weekday_6  \n",
       "0          0          0          0          1  \n",
       "1          0          0          0          1  \n",
       "2          0          0          0          1  \n",
       "3          0          0          0          1  \n",
       "4          0          0          0          1  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_fields = ['season', 'weathersit', 'mnth', 'hr', 'weekday']\n",
    "for each in dummy_fields:\n",
    "    dummies = pd.get_dummies(rides[each], prefix=each, drop_first=False)\n",
    "    rides = pd.concat([rides, dummies], axis=1)\n",
    "\n",
    "fields_to_drop = ['instant', 'dteday', 'season', 'weathersit', \n",
    "                  'weekday', 'atemp', 'mnth', 'workingday', 'hr']\n",
    "data = rides.drop(fields_to_drop, axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quant_features = ['casual', 'registered', 'cnt', 'temp', 'hum', 'windspeed']\n",
    "# Store scalings in a dictionary so we can convert back later\n",
    "scaled_features = {}\n",
    "for each in quant_features:\n",
    "    mean, std = data[each].mean(), data[each].std()\n",
    "    scaled_features[each] = [mean, std]\n",
    "    data.loc[:, each] = (data[each] - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save data for approximately the last 21 days \n",
    "test_data = data[-21*24:]\n",
    "\n",
    "# Now remove the test data from the data set \n",
    "data = data[:-21*24]\n",
    "\n",
    "# Separate the data into features and targets\n",
    "target_fields = ['cnt', 'casual', 'registered']\n",
    "features, targets = data.drop(target_fields, axis=1), data[target_fields]\n",
    "test_features, test_targets = test_data.drop(target_fields, axis=1), test_data[target_fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hold out the last 60 days or so of the remaining data as a validation set\n",
    "train_features, train_targets = features[:-60*24], targets[:-60*24]\n",
    "val_features, val_targets = features[-60*24:], targets[-60*24:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a single layer neural network with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15435, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440, 56)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cnt</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15435</th>\n",
       "      <td>3.580933</td>\n",
       "      <td>-0.054279</td>\n",
       "      <td>4.309096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15436</th>\n",
       "      <td>0.973258</td>\n",
       "      <td>-0.013715</td>\n",
       "      <td>1.170827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15437</th>\n",
       "      <td>0.151813</td>\n",
       "      <td>-0.175970</td>\n",
       "      <td>0.239256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15438</th>\n",
       "      <td>0.559779</td>\n",
       "      <td>0.351359</td>\n",
       "      <td>0.556386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15439</th>\n",
       "      <td>1.105571</td>\n",
       "      <td>0.858407</td>\n",
       "      <td>1.045296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            cnt    casual  registered\n",
       "15435  3.580933 -0.054279    4.309096\n",
       "15436  0.973258 -0.013715    1.170827\n",
       "15437  0.151813 -0.175970    0.239256\n",
       "15438  0.559779  0.351359    0.556386\n",
       "15439  1.105571  0.858407    1.045296"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neural_net(input, num_features):\n",
    "    # Build input layer\n",
    "    labels_count = 1\n",
    "\n",
    "    num_hidden = 8\n",
    "\n",
    "    weights_i_h = tf.Variable(tf.truncated_normal((num_features, num_hidden)))\n",
    "    biases_i_h = tf.Variable(tf.zeros(num_hidden))\n",
    "\n",
    "    weights_h_o = tf.Variable(tf.truncated_normal((num_hidden, labels_count)))\n",
    "    biases_h_o = tf.Variable(tf.zeros(labels_count))\n",
    "    \n",
    "    logits_i_h = tf.matmul(inputs, weights_i_h) + biases_i_h # when to use tf.add?\n",
    "    sigmoid_i_h = tf.nn.sigmoid(logits_i_h, name=None)\n",
    "\n",
    "    prediction = tf.matmul(sigmoid_i_h, weights_h_o) + biases_h_o\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_neural_network(x, num_features):\n",
    "    prediction = neural_net(x, num_features) #feed-forward\n",
    "    loss = tf.reduce_mean(tf.squared_difference(prediction, label))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(loss)    # default learning_rate = 0.001\n",
    "\n",
    "    # cycles of feedforwards + backprop\n",
    "    hm_epochs = 10000\n",
    "    training_fd = {inputs: train_features, label: train_targets[\"cnt\"][:,None]}\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(hm_epochs):      \n",
    "            _, c = sess.run([optimizer, loss], feed_dict = training_fd)\n",
    "            if (epoch % 1000 == 0 or epoch == 9999):\n",
    "                print(\"Epoch\", epoch, \"completed out of\", hm_epochs, \"loss:\", c)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 completed out of 10000 loss: 3.07567\n",
      "Epoch 1000 completed out of 10000 loss: 0.381853\n",
      "Epoch 2000 completed out of 10000 loss: 0.251948\n",
      "Epoch 3000 completed out of 10000 loss: 0.23161\n",
      "Epoch 4000 completed out of 10000 loss: 0.220295\n",
      "Epoch 5000 completed out of 10000 loss: 0.20794\n",
      "Epoch 6000 completed out of 10000 loss: 0.191656\n",
      "Epoch 7000 completed out of 10000 loss: 0.174035\n",
      "Epoch 8000 completed out of 10000 loss: 0.158193\n",
      "Epoch 9000 completed out of 10000 loss: 0.142858\n",
      "Epoch 9999 completed out of 10000 loss: 0.124601\n"
     ]
    }
   ],
   "source": [
    "num_features = train_features.shape[1]\n",
    "labels_count = 1\n",
    "inputs = tf.placeholder(tf.float32, [None, num_features])\n",
    "label = tf.placeholder(tf.float32, [None, labels_count])\n",
    "train_neural_network(inputs, num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Adding more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def two_hidden_layer_nn(input, num_features):\n",
    "    # Build input layer\n",
    "    labels_count = 1\n",
    "\n",
    "    # layer 1\n",
    "    num_hidden_1 = 8\n",
    "    weights_i_h1 = tf.Variable(tf.truncated_normal((num_features, num_hidden_1)))\n",
    "    biases_i_h1 = tf.Variable(tf.zeros(num_hidden_1))\n",
    "    logits_i_h1 = tf.matmul(inputs, weights_i_h1) + biases_i_h1 # when to use tf.add?\n",
    "    sigmoid_i_h1 = tf.nn.sigmoid(logits_i_h1, name=None)\n",
    "    \n",
    "    #layer 2\n",
    "    num_hidden_2 = 8\n",
    "    weights_h1_h2 = tf.Variable(tf.truncated_normal((num_hidden_1, num_hidden_2)))\n",
    "    biases_h1_h2 = tf.Variable(tf.zeros(num_hidden_2))\n",
    "    logits_h1_h2 = tf.matmul(sigmoid_i_h1, weights_h1_h2) + biases_h1_h2 # when to use tf.add?\n",
    "    sigmoid_h1_h2 = tf.nn.sigmoid(logits_h1_h2, name=None)\n",
    "    \n",
    "    #output\n",
    "    weights_h2_o = tf.Variable(tf.truncated_normal((num_hidden_2, labels_count)))\n",
    "    biases_h2_o = tf.Variable(tf.zeros(labels_count))\n",
    "    prediction = tf.matmul(sigmoid_h1_h2, weights_h2_o) + biases_h2_o\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_two_hidden_nn(x, num_features):\n",
    "    prediction = two_hidden_layer_nn(x, num_features) #feed-forward\n",
    "    loss = tf.reduce_mean(tf.squared_difference(prediction, label))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(loss)    # default learning_rate = 0.001\n",
    "\n",
    "    # cycles of feedforwards + backprop\n",
    "    hm_epochs = 10000\n",
    "    training_fd = {inputs: train_features, label: train_targets[\"cnt\"][:,None]}\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in tqdm(range(hm_epochs)):      \n",
    "            _, c = sess.run([optimizer, loss], feed_dict = training_fd)\n",
    "            if (epoch % 1000 == 0 or epoch == 9999):\n",
    "                print(\"Epoch\", epoch, \"completed out of\", hm_epochs, \"loss:\", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/10000 [00:00<05:47, 28.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 completed out of 10000 loss: 3.27467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1006/10000 [00:31<04:35, 32.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 completed out of 10000 loss: 0.365089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2005/10000 [01:02<04:11, 31.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2000 completed out of 10000 loss: 0.255045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3004/10000 [01:33<03:35, 32.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3000 completed out of 10000 loss: 0.213738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4004/10000 [02:04<03:03, 32.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4000 completed out of 10000 loss: 0.180843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5004/10000 [02:35<02:33, 32.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5000 completed out of 10000 loss: 0.153527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6004/10000 [03:05<02:05, 31.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6000 completed out of 10000 loss: 0.129921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7004/10000 [03:35<01:29, 33.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7000 completed out of 10000 loss: 0.10912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8004/10000 [04:06<01:06, 30.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8000 completed out of 10000 loss: 0.0929927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9004/10000 [04:36<00:30, 32.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9000 completed out of 10000 loss: 0.0826212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [05:07<00:00, 33.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9999 completed out of 10000 loss: 0.0763712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_two_hidden_nn(inputs, num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactor code to allow for saving and loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = train_features.shape[1]\n",
    "labels_count = 1\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, [None, num_features])\n",
    "label = tf.placeholder(tf.float32, [None, labels_count])\n",
    "\n",
    "# layer 1\n",
    "num_hidden_1 = 8\n",
    "weights_i_h1 = tf.Variable(tf.truncated_normal((num_features, num_hidden_1)))\n",
    "biases_i_h1 = tf.Variable(tf.zeros(num_hidden_1))\n",
    "logits_i_h1 = tf.matmul(inputs, weights_i_h1) + biases_i_h1 # when to use tf.add?\n",
    "sigmoid_i_h1 = tf.nn.sigmoid(logits_i_h1, name=None)\n",
    "\n",
    "#layer 2\n",
    "num_hidden_2 = 8\n",
    "weights_h1_h2 = tf.Variable(tf.truncated_normal((num_hidden_1, num_hidden_2)))\n",
    "biases_h1_h2 = tf.Variable(tf.zeros(num_hidden_2))\n",
    "logits_h1_h2 = tf.matmul(sigmoid_i_h1, weights_h1_h2) + biases_h1_h2 # when to use tf.add?\n",
    "sigmoid_h1_h2 = tf.nn.sigmoid(logits_h1_h2, name=None)\n",
    "\n",
    "#output\n",
    "weights_h2_o = tf.Variable(tf.truncated_normal((num_hidden_2, labels_count)))\n",
    "biases_h2_o = tf.Variable(tf.zeros(labels_count))\n",
    "prediction = tf.matmul(sigmoid_h1_h2, weights_h2_o) + biases_h2_o\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/10000 [00:00<07:10, 23.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 completed out of 10000 loss: 1.04927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1005/10000 [00:30<04:30, 33.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 completed out of 10000 loss: 0.42554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2005/10000 [01:00<04:03, 32.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2000 completed out of 10000 loss: 0.250728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3005/10000 [01:31<03:31, 33.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3000 completed out of 10000 loss: 0.196325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4006/10000 [02:01<03:03, 32.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4000 completed out of 10000 loss: 0.15674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5006/10000 [02:31<02:30, 33.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5000 completed out of 10000 loss: 0.128069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6006/10000 [03:02<02:04, 32.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6000 completed out of 10000 loss: 0.108479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7007/10000 [03:32<01:23, 35.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7000 completed out of 10000 loss: 0.096413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8006/10000 [04:02<01:01, 32.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8000 completed out of 10000 loss: 0.0891278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9005/10000 [04:33<00:30, 33.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9000 completed out of 10000 loss: 0.0843493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [05:02<00:00, 33.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9999 completed out of 10000 loss: 0.0809066\n",
      "model.ckpt\n"
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_mean(tf.squared_difference(prediction, label))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(loss)    # default learning_rate = 0.001\n",
    "\n",
    "# cycles of feedforwards + backprop\n",
    "hm_epochs = 10000\n",
    "training_fd = {inputs: train_features, label: train_targets[\"cnt\"][:,None]}\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in tqdm(range(hm_epochs)):      \n",
    "        _, c = sess.run([optimizer, loss], feed_dict = training_fd)\n",
    "        if (epoch % 1000 == 0 or epoch == 9999):\n",
    "            print(\"Epoch\", epoch, \"completed out of\", hm_epochs, \"loss:\", c)\n",
    "    save_path = saver.save(sess, \"model.ckpt\")\n",
    "    print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.277086\n"
     ]
    }
   ],
   "source": [
    "# load model from checkpoint and calculate loss for test data\n",
    "with tf.Session() as sess:\n",
    "    testing_fd = {inputs: test_features, label: test_targets[\"cnt\"][:,None]}\n",
    "    saver.restore(sess, \"./model.ckpt\")\n",
    "    print(sess.run(loss, feed_dict=testing_fd))\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "py35",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
